{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff29363a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"임승혁 수정wjd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35ed3122-30d0-427e-9b0f-58dd944bae08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import requests\n",
    "import bs4\n",
    "import pandas\n",
    "import re\n",
    "import time\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "feb6b927-a81c-4ff2-95ce-0176b5b3faeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "now = datetime.datetime.now()\n",
    "year = now.isoformat()[0:4]\n",
    "month = now.isoformat()[5:7]\n",
    "day = now.isoformat()[8:10]\n",
    "date = year+month+day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2377d42-a5c3-4b32-88e9-5c65ac8621c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023-05-20'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now.isoformat()[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddc18a35-b8f7-485e-a58c-2ecb7e6a919e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://finance.naver.com/research/company_list.naver?keyword=&brokerCode=&searchType=writeDate&writeFromDate=2018-01-01&writeToDate=2023-05-19&itemName=&itemCode=&x=0&y=0&page=\n"
     ]
    }
   ],
   "source": [
    "url = f'https://finance.naver.com/research/company_list.naver\\\n",
    "?keyword=&brokerCode=&searchType=\\\n",
    "writeDate&writeFromDate=2018-01-01&writeToDate=2023-05-19&itemName=&itemCode=&x=0&y=0&page='\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d5da5a-5976-4f66-b79b-a1c7684e62f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"민정\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacfc5fb-2518-464b-b3d8-d25a26d0d10f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac94164-f2e6-45c0-84fc-106208c5aedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "    link = soup.select('td.content li dt a')\n",
    "    f_link_list = list(set([i.attrs['href'] for i in link]))\n",
    "    link_list.append(f_link_list)\n",
    "    addr = soup.find_all('a', {'class':'nclicks(fls.page)'})\n",
    "\n",
    "    next_button = soup.find('a', {'class':'next'})\n",
    "    if next_button:\n",
    "        page += 1\n",
    "\n",
    "    elif next_button is None:\n",
    "        numlist = [i.get_text() for i in addr][1:]\n",
    "        for page in numlist:\n",
    "            page_url = url + str(page)\n",
    "            response = requests.get(page_url, headers={'User-Agent': 'Mozill4a/5.0'})\n",
    "            soup = bs4.BeautifulSoup(response.text, 'html.parser')\n",
    "            link = soup.select('td.content li dt a')\n",
    "            f_link_list = list(set([i.attrs['href'] for i in link]))\n",
    "            link_list.append(f_link_list)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32dfd815-144b-4d44-a6fc-cccc34c9428b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 721/721 [03:42<00:00,  3.24it/s]\n"
     ]
    }
   ],
   "source": [
    "page = 1\n",
    "next_link_text = \"다음\"\n",
    "stock_name_list = []\n",
    "link_list = []\n",
    "\n",
    "page_url = url + str(page)\n",
    "response = requests.get(page_url, headers={'User-Agent': 'Mozill4a/5.0'})\n",
    "soup = bs4.BeautifulSoup(response.text, 'html.parser')\n",
    "last_page = soup.select('table tr td a')[-6]['href'].split('/')[-1].split('=')[-1]\n",
    "\n",
    "for _ in tqdm(range(int(last_page))):\n",
    "    \n",
    "    page_url = url + str(page)\n",
    "    response = requests.get(page_url, headers={'User-Agent': 'Mozill4a/5.0'})\n",
    "    soup = bs4.BeautifulSoup(response.text, 'html.parser')\n",
    "    stock_name = soup.select('table a.stock_item')[0:30]\n",
    "    link = soup.select('table td:nth-child(2) a')[:-6]\n",
    "    for i in range(len(soup.select('table a[target]'))):\n",
    "        stock_name_list.append(stock_name[i].text)\n",
    "        link_list.append('https://finance.naver.com/research/' + link[i]['href'])\n",
    "    page += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cebcefa-6504-4621-8fdb-0fe03754218c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21619"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(link_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d844782d-09c8-4287-991d-fb6ef6c549e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "options = webdriver.ChromeOptions()\n",
    "# 창 숨기는 옵션 추가\n",
    "options.add_argument(\"headless\")\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "driver.get(link_list[0])\n",
    "text = driver.find_element(By.XPATH, '//*[@id=\"contentarea_left\"]/div[2]/table/tbody/tr[1]/th[1]/p')\n",
    "broker = text.text.split('|')[0]\n",
    "time = text.text.split('|')[1]\n",
    "view_cnt = ''.join(filter(str.isdigit, text.text.split('|')[2]))\n",
    "\n",
    "text = driver.find_element(By.XPATH, '//*[@id=\"contentarea_left\"]/div[2]/table/tbody/tr[1]/th[1]/span/em')\n",
    "stock_name = text.text\n",
    "text = driver.find_element(By.CSS_SELECTOR, 'th.view_sbj')\n",
    "title = text.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "77ca576f-7d9a-44ef-8904-1a332b309086",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SK스퀘어 Harvest and Return 30~50%\\nDS투자증권|2023.05.18|조회 651'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/html/body/div[3]/div[2]/div[2]/div[1]/div[2]/table/tbody/tr[1]/th[1]/text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae5ff68-54ea-4eb6-9df6-0686d0cb3e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "time_list = []\n",
    "company_list = []\n",
    "title_list = []\n",
    "main_txt_list = []\n",
    "http_link = []\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "# 창 숨기는 옵션 추가\n",
    "options.add_argument(\"headless\")\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "for link in tqdm(link_list):\n",
    "    try:\n",
    "        driver.get(link)\n",
    "        text = driver.find_element(By.XPATH, '//*[@id=\"ct\"]/div[1]/div[3]/div[1]/div[1]/span')\n",
    "        post_time = text.text\n",
    "        text = driver.find_element(By.XPATH, '//*[@id=\"ct\"]/div[1]/div[1]/a/img[1]')\n",
    "        company = text.get_attribute('alt')\n",
    "        text = driver.find_element(By.XPATH, '//*[@id=\"title_area\"]/span')\n",
    "        title = text.text\n",
    "        text = driver.find_element(By.XPATH, '//*[@id=\"dic_area\"]')\n",
    "        main_txt = text.text\n",
    "\n",
    "        time_list.append(post_time)\n",
    "        company_list.append(company)\n",
    "        title_list.append(title)\n",
    "        main_txt_list.append(main_txt)\n",
    "        http_link.append(link)\n",
    "\n",
    "    except:\n",
    "        continue\n",
    "df = pd.DataFrame({'분류':index, '시간':time_list, '언론사':company_list, '제목':title_list, '본문':main_txt_list, '링크':http_link})\n",
    "return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78d0225-07f1-42d6-8f9d-13e009ad7138",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73b6b41-ab0e-4862-89ae-05d54ec4f16c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b8f75b-a016-4949-b1a5-c9cf30904290",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b5102f-ee8d-456c-9872-68627d70597c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6dbc0b-cf57-4e02-9a5a-ef06104ebf60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e758b7-0dd4-4c0b-9591-a42615d327ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9eda77b-7d78-4ad5-bf93-50033315ea71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8baea825-015e-47d9-ad99-f8cabc7d4a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = 'C:/myPyCode/news_csv/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "849f47c2-0fe3-40aa-8701-9cce3158a576",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:34<00:00,  5.77s/it]\n",
      " 25%|█████████████████████                                                               | 2/8 [00:19<00:57,  9.66s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_28784\\1416973021.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m'*.csv'\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsv_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[0mpolitic_list_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlink_parser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpolitic_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'정치'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m         \u001b[0meconomy_list_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlink_parser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meconomy_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'경제'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m         \u001b[0msociety_list_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlink_parser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msociety_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'사회'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[0mlife_culture_list_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlink_parser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlife_culture_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'생활_문화'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_28784\\1416973021.py\u001b[0m in \u001b[0;36mlink_parser\u001b[1;34m(url_list, category)\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0mpage_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murl\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'User-Agent'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Mozill4a/5.0'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m             \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbs4\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'html.parser'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0mlink\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'td.content li dt a'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m     \"\"\"\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"get\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    585\u001b[0m         }\n\u001b[0;32m    586\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 587\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    699\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 701\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    702\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    487\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m                 resp = conn.urlopen(\n\u001b[0m\u001b[0;32m    490\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m                     \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    702\u001b[0m             \u001b[1;31m# Make the request on the httplib connection object.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 703\u001b[1;33m             httplib_response = self._make_request(\n\u001b[0m\u001b[0;32m    704\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    705\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    447\u001b[0m                     \u001b[1;31m# Python 3 (including for exceptions like SystemExit).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m                     \u001b[1;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m                     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    442\u001b[0m                 \u001b[1;31m# Python 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 444\u001b[1;33m                     \u001b[0mhttplib_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    445\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m                     \u001b[1;31m# Remove the TypeError from the exception chain in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1375\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1376\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1377\u001b[1;33m                 \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1378\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1379\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mbegin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    318\u001b[0m         \u001b[1;31m# read until we get a non-100 response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m             \u001b[0mversion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    321\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 281\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"iso-8859-1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    282\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"status line\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    702\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 704\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    705\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1240\u001b[0m                   \u001b[1;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m                   self.__class__)\n\u001b[1;32m-> 1242\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1243\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1244\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1098\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def link_parser(url_list : list, category : str) -> list:\n",
    "    \n",
    "    for url in tqdm(url_list):\n",
    "        page = 1\n",
    "        next_link_text = \"다음\"\n",
    "        link_list = []\n",
    "        while True:\n",
    "            page_url = url + str(page)\n",
    "\n",
    "            response = requests.get(page_url, headers={'User-Agent': 'Mozill4a/5.0'})\n",
    "            soup = bs4.BeautifulSoup(response.text, 'html.parser')\n",
    "            link = soup.select('td.content li dt a')\n",
    "            f_link_list = list(set([i.attrs['href'] for i in link]))\n",
    "            link_list.append(f_link_list)\n",
    "            addr = soup.find_all('a', {'class':'nclicks(fls.page)'})\n",
    "\n",
    "            next_button = soup.find('a', {'class':'next'})\n",
    "            if next_button:\n",
    "                page += 1\n",
    "\n",
    "            elif next_button is None:\n",
    "                numlist = [i.get_text() for i in addr][1:]\n",
    "                for page in numlist:\n",
    "                    page_url = url + str(page)\n",
    "                    response = requests.get(page_url, headers={'User-Agent': 'Mozill4a/5.0'})\n",
    "                    soup = bs4.BeautifulSoup(response.text, 'html.parser')\n",
    "                    link = soup.select('td.content li dt a')\n",
    "                    f_link_list = list(set([i.attrs['href'] for i in link]))\n",
    "                    link_list.append(f_link_list)\n",
    "                break\n",
    "    \n",
    "    link_list = [j for i in link_list for j in i]\n",
    "    if old_link2 == 0:\n",
    "        total_link = link_list\n",
    "        additional_link = list(set(total_link))\n",
    "        df = pd.DataFrame({'링크':total_link})\n",
    "        df.to_csv(csv_path + f'{category}.csv')\n",
    "    else:\n",
    "        total_link = old_link2 + link_list\n",
    "        total_link = list(set(total_link))\n",
    "        df = pd.DataFrame({'링크':total_link})\n",
    "        df.to_csv(csv_path + f'{category}.csv')\n",
    "        additional_link = [i for i in total_link if i not in old_link2]\n",
    "    return additional_link\n",
    "\n",
    "\n",
    "def get_txt(link_list : list, index : str):\n",
    "\n",
    "    time_list = []\n",
    "    company_list = []\n",
    "    title_list = []\n",
    "    main_txt_list = []\n",
    "    http_link = []\n",
    "    csv_path = 'C:/myPyCode/news_csv/'\n",
    "    \n",
    "    options = webdriver.ChromeOptions()\n",
    "    # 창 숨기는 옵션 추가\n",
    "    options.add_argument(\"headless\")\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "        \n",
    "    for link in tqdm(link_list):\n",
    "        try:\n",
    "            driver.get(link)\n",
    "            text = driver.find_element(By.XPATH, '//*[@id=\"ct\"]/div[1]/div[3]/div[1]/div[1]/span')\n",
    "            post_time = text.text\n",
    "            text = driver.find_element(By.XPATH, '//*[@id=\"ct\"]/div[1]/div[1]/a/img[1]')\n",
    "            company = text.get_attribute('alt')\n",
    "            text = driver.find_element(By.XPATH, '//*[@id=\"title_area\"]/span')\n",
    "            title = text.text\n",
    "            text = driver.find_element(By.XPATH, '//*[@id=\"dic_area\"]')\n",
    "            main_txt = text.text\n",
    "\n",
    "            time_list.append(post_time)\n",
    "            company_list.append(company)\n",
    "            title_list.append(title)\n",
    "            main_txt_list.append(main_txt)\n",
    "            http_link.append(link)\n",
    "            \n",
    "        except:\n",
    "            continue\n",
    "    df = pd.DataFrame({'분류':index, '시간':time_list, '언론사':company_list, '제목':title_list, '본문':main_txt_list, '링크':http_link})\n",
    "    return df\n",
    "\n",
    "def main():\n",
    "    start_time = time.time()\n",
    "    if '*.csv' not in os.listdir(csv_path):\n",
    "        politic_list_ = link_parser(politic_list, '정치')\n",
    "        economy_list_ = link_parser(economy_list, '경제')\n",
    "        society_list_ = link_parser(society_list, '사회')\n",
    "        life_culture_list_ = link_parser(life_culture_list, '생활_문화')\n",
    "        IT_science_list_ = link_parser(IT_science_list, 'IT_과학')\n",
    "        world_list_ = link_parser(world_list, '세계')\n",
    "        politic_df = get_txt(politic_list_, '정치')\n",
    "        economy_df = get_txt(economy_list_, '경제')\n",
    "        society_df = get_txt(society_list_, '사회')\n",
    "        life_culture_df = get_txt(life_culture_list_, '생활_문화')\n",
    "        IT_science_df = get_txt(IT_science_list_, 'IT_과학')\n",
    "        world_df = get_txt(world_list_, '세계')\n",
    "        news_df = pd.concat([politic_df, economy_df, society_df, life_culture_df, IT_science_df, world_df], axis = 0)\n",
    "        news_df.to_csv(csv_path + 'news_df.csv')\n",
    "        end_time = time.time()\n",
    "        print('걸린 시간 :', (end_time - start_time) / 60, '분')\n",
    "        print('크롤링 완료')\n",
    "    else:\n",
    "        politic_list_ = link_parser(politic_list, '정치')\n",
    "        economy_list_ = link_parser(economy_list, '경제')\n",
    "        society_list_ = link_parser(society_list, '사회')\n",
    "        life_culture_list_ = link_parser(life_culture_list, '생활_문화')\n",
    "        IT_science_list_ = link_parser(IT_science_list, 'IT_과학')\n",
    "        world_list_ = link_parser(world_list, '세계')\n",
    "        politic_df = get_txt(politic_list_, '정치')\n",
    "        economy_df = get_txt(economy_list_, '경제')\n",
    "        society_df = get_txt(society_list_, '사회')\n",
    "        life_culture_df = get_txt(life_culture_list_, '생활_문화')\n",
    "        IT_science_df = get_txt(IT_science_list_, 'IT_과학')\n",
    "        world_df = get_txt(world_list_, '세계')\n",
    "        news_df_old = pd.read_csv(csv_path + 'news_df.csv')\n",
    "        news_df = pd.concat([news_df_old, politic_df, economy_df, society_df, life_culture_df, IT_science_df, world_df], axis = 0)\n",
    "        news_df.to_csv(csv_path + 'news_df.csv')\n",
    "        end_time = time.time()\n",
    "        print('걸린 시간 :', (end_time - start_time) / 60, '분')\n",
    "        print('크롤링 완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a912ceba-df20-4f05-a487-7ff15b99e10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:10<00:00,  2.20s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "pool = multiprocessing.Pool(processes=1) # 6개의 processes 사용\n",
    "# politic_list_ = link_parser(politic_list, '정치')\n",
    "# economy_list_ = link_parser(economy_list, '경제')\n",
    "# society_list_ = link_parser(society_list, '사회')\n",
    "# life_culture_list_ = link_parser(life_culture_list, '생활/문화')\n",
    "# IT_science_list_ = link_parser(IT_science_list, 'IT/과학')\n",
    "world_list_ = link_parser(world_list, '세계')\n",
    "# pool.map(get_txt, politic_list_)\n",
    "# pool.map(get_txt, economy_list_)\n",
    "# pool.map(get_txt, society_list_)\n",
    "# pool.map(get_txt, life_culture_list_)\n",
    "# pool.map(get_txt, IT_science_list_)\n",
    "pool.map(get_txt, world_list_)\n",
    "pool.close()\n",
    "pool.join()\n",
    "end_time = time.time()\n",
    "print('걸린 시간 :', (end_time - start_time) / 60, '분')\n",
    "print('크롤링 완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c20c75d-5d4f-44ff-ad89-3f16a736f319",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:08<00:00,  1.67s/it]\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "main()\n",
    "end_time = time.time()\n",
    "print('걸린 시간 :', (end_time - start_time) / 60, '분')\n",
    "print('크롤링 완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "631f68a6-825e-4c8c-b5d0-c7a8bcd0cbd5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_txt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13832\\988680047.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_txt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'get_txt' is not defined"
     ]
    }
   ],
   "source": [
    "get_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367122bd-6d11-43ba-a883-12a3a09c8c94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6abfc544-fd08-4aa1-a197-f4a47857bbd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IT_과학.csv',\n",
       " 'news_df.csv',\n",
       " '경제.csv',\n",
       " '사회.csv',\n",
       " '생활_문화.csv',\n",
       " '세계.csv',\n",
       " '정치.csv']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "167d3be7-fb00-4416-aced-5111b04dd421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IT_과학.csv',\n",
       " 'news_df.csv',\n",
       " '경제.csv',\n",
       " '사회.csv',\n",
       " '생활_문화.csv',\n",
       " '세계.csv',\n",
       " '정치.csv']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list_csv = [file for file in os.listdir(csv_path) if file.endswith(\".csv\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a15f570-77cc-4efa-8b1c-4d4f4ab0ece1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44ebab2c-95cf-4d8b-87d6-3f96c59b7fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:07<00:00,  1.55s/it]\n"
     ]
    }
   ],
   "source": [
    "for url in tqdm(world_list):\n",
    "    page = 1\n",
    "    next_link_text = \"다음\"\n",
    "    link_list = []\n",
    "    while True:\n",
    "        page_url = url + str(page)\n",
    "\n",
    "        response = requests.get(page_url, headers={'User-Agent': 'Mozill4a/5.0'})\n",
    "        soup = bs4.BeautifulSoup(response.text, 'html.parser')\n",
    "        link = soup.select('td.content li dt a')\n",
    "        f_link_list = list(set([i.attrs['href'] for i in link]))\n",
    "        link_list.append(f_link_list)\n",
    "        addr = soup.find_all('a', {'class':'nclicks(fls.page)'})\n",
    "\n",
    "        next_button = soup.find('a', {'class':'next'})\n",
    "        if next_button:\n",
    "            page += 1\n",
    "\n",
    "        elif next_button is None:\n",
    "            numlist = [i.get_text() for i in addr][1:]\n",
    "            for page in numlist:\n",
    "                page_url = url + str(page)\n",
    "                response = requests.get(page_url, headers={'User-Agent': 'Mozill4a/5.0'})\n",
    "                soup = bs4.BeautifulSoup(response.text, 'html.parser')\n",
    "                link = soup.select('td.content li dt a')\n",
    "                f_link_list = list(set([i.attrs['href'] for i in link]))\n",
    "                link_list.append(f_link_list)\n",
    "            break\n",
    "\n",
    "link_list = [j for i in link_list for j in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5219a2-4cf5-41e9-b2e4-743b7f902379",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a1cd382-0851-4fb7-925a-94678212f9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    }
   ],
   "source": [
    "time_list = []\n",
    "company_list = []\n",
    "title_list = []\n",
    "main_txt_list = []\n",
    "http_link = []\n",
    "csv_path = 'C:/myPyCode/news_csv/'\n",
    "\n",
    "if link_list[0][-3:] == '100':index = '정치'\n",
    "if link_list[0][-3:] == '101':index = '경제'\n",
    "if link_list[0][-3:] == '102':index = '사회'\n",
    "if link_list[0][-3:] == '103':index = '생활/문화'\n",
    "if link_list[0][-3:] == '104':index = '세계'\n",
    "if link_list[0][-3:] == '105':index = 'IT/과학'\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "# 창 숨기는 옵션 추가\n",
    "options.add_argument(\"headless\")\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "for link in tqdm(link_list[0:10]):\n",
    "    try:\n",
    "        driver.get(link)\n",
    "        text = driver.find_element(By.XPATH, '//*[@id=\"ct\"]/div[1]/div[3]/div[1]/div[1]/span')\n",
    "        post_time = text.text\n",
    "        text = driver.find_element(By.XPATH, '//*[@id=\"ct\"]/div[1]/div[1]/a/img[1]')\n",
    "        company = text.get_attribute('alt')\n",
    "        text = driver.find_element(By.XPATH, '//*[@id=\"title_area\"]/span')\n",
    "        title = text.text\n",
    "        text = driver.find_element(By.XPATH, '//*[@id=\"dic_area\"]')\n",
    "        main_txt = text.text\n",
    "\n",
    "        time_list.append(post_time)\n",
    "        company_list.append(company)\n",
    "        title_list.append(title)\n",
    "        main_txt_list.append(main_txt)\n",
    "        http_link.append(link)\n",
    "\n",
    "    except:\n",
    "        continue\n",
    "df = pd.DataFrame({'분류':index, '시간':time_list, '언론사':company_list, '제목':title_list, '본문':main_txt_list, '링크':http_link})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f4737cf-d590-4812-9161-73147714bd25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>분류</th>\n",
       "      <th>시간</th>\n",
       "      <th>언론사</th>\n",
       "      <th>제목</th>\n",
       "      <th>본문</th>\n",
       "      <th>링크</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>세계</td>\n",
       "      <td>2023.03.15. 오후 4:24</td>\n",
       "      <td>SBS</td>\n",
       "      <td>\"러시아, 여성 죄수들도 우크라 전장 내보내\"</td>\n",
       "      <td>우크라이나 전쟁에 남성 죄수들을 용병으로 투입했던 러시아가 여성 죄수들까지 전장에 ...</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/055/000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>세계</td>\n",
       "      <td>2023.03.15. 오후 4:00</td>\n",
       "      <td>조선비즈</td>\n",
       "      <td>[Why] “예금 전액 보호” 美 SVB 구제책에 비난 여론 불거진 이유</td>\n",
       "      <td>로이터=연합뉴스\\n\\n미국 실리콘밸리은행(SVB) 파산 사태에 조 바이든 미 행정부...</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/366/000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>세계</td>\n",
       "      <td>2023.03.15. 오후 3:46</td>\n",
       "      <td>한국일보</td>\n",
       "      <td>냉전 후 첫 충돌한 미국·러시아 군용기...확전 피했지만 긴장 여전</td>\n",
       "      <td>러 Su-27 전투기, 미 MQ-9 무인기 프로펠러 충돌\\n미 무인기 흑해 해상 추...</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/469/000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>세계</td>\n",
       "      <td>2023.03.15. 오후 3:45</td>\n",
       "      <td>조선일보</td>\n",
       "      <td>“손 씻으면 싫어해”…日 유명 튀김집 직원, 1달만에 퇴사한 이유 폭로</td>\n",
       "      <td>일본의 한 '쿠시카츠 다나카' 매장. (기사 내용과는 관련 없는 매장 사진)/'쿠시...</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/023/000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>세계</td>\n",
       "      <td>2023.03.15. 오후 4:33</td>\n",
       "      <td>데일리안</td>\n",
       "      <td>美 법무·증권거래위원회, 'SVB 파산' 조사 착수</td>\n",
       "      <td>\"예비조사 단계…기소·고발 안 이어질 듯\"\\n파산 전 경영진 지분 매각 조사 대상\\...</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/119/000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>세계</td>\n",
       "      <td>2023.03.15. 오후 4:22</td>\n",
       "      <td>MBC</td>\n",
       "      <td>\"러시아, 여성 죄수들도 우크라 전장 내보내\"</td>\n",
       "      <td>포격당한 러시아 치하 우크라이나 볼노바카 마을, 군 조사관 모습 [자료사진]\\n우크...</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/214/000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>세계</td>\n",
       "      <td>2023.03.15. 오후 4:10</td>\n",
       "      <td>서울경제</td>\n",
       "      <td>메타, 넉 달 만에 1만 명 또 자른다…\"올해는 '효율의 해'\"</td>\n",
       "      <td>감원 발표한 빅테크 중 첫 2차 구조조정\\n우선순위 낮은 프로젝트 폐기 계획도\\n2...</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/011/000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>세계</td>\n",
       "      <td>2023.03.15. 오후 4:10</td>\n",
       "      <td>서울경제</td>\n",
       "      <td>‘퇴출 위기’ 틱톡, 中 모기업과 분리 검토</td>\n",
       "      <td>“최후의 수단으로 ‘기업 분할’ 검토”\\n글로벌 퇴출 우려에 자구책 고심\\n틱톡. ...</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/011/000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>세계</td>\n",
       "      <td>2023.03.15. 오후 3:57</td>\n",
       "      <td>SBS</td>\n",
       "      <td>[D리포트] 중국 공업용 세제 원료로 해삼 · 전복 가공</td>\n",
       "      <td>[중국 공업용 세제 원료로 해삼·전복 가공]\\n\\n중국 동북부 다롄의 한 수산물 업...</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/055/000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>세계</td>\n",
       "      <td>2023.03.15. 오후 4:03</td>\n",
       "      <td>데일리안</td>\n",
       "      <td>성병 갖고 태어났다...캐나다 '선천성 매독' 신생아 13배 급증, 이유는?</td>\n",
       "      <td>ⓒgettyimagesBank\\n[데일리안 = 박상우 기자] 캐나다에서 매독에 걸린...</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/119/000...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   분류                   시간   언론사                                          제목  \\\n",
       "0  세계  2023.03.15. 오후 4:24   SBS                   \"러시아, 여성 죄수들도 우크라 전장 내보내\"   \n",
       "1  세계  2023.03.15. 오후 4:00  조선비즈    [Why] “예금 전액 보호” 美 SVB 구제책에 비난 여론 불거진 이유   \n",
       "2  세계  2023.03.15. 오후 3:46  한국일보       냉전 후 첫 충돌한 미국·러시아 군용기...확전 피했지만 긴장 여전   \n",
       "3  세계  2023.03.15. 오후 3:45  조선일보     “손 씻으면 싫어해”…日 유명 튀김집 직원, 1달만에 퇴사한 이유 폭로   \n",
       "4  세계  2023.03.15. 오후 4:33  데일리안                美 법무·증권거래위원회, 'SVB 파산' 조사 착수   \n",
       "5  세계  2023.03.15. 오후 4:22   MBC                   \"러시아, 여성 죄수들도 우크라 전장 내보내\"   \n",
       "6  세계  2023.03.15. 오후 4:10  서울경제         메타, 넉 달 만에 1만 명 또 자른다…\"올해는 '효율의 해'\"   \n",
       "7  세계  2023.03.15. 오후 4:10  서울경제                    ‘퇴출 위기’ 틱톡, 中 모기업과 분리 검토   \n",
       "8  세계  2023.03.15. 오후 3:57   SBS             [D리포트] 중국 공업용 세제 원료로 해삼 · 전복 가공   \n",
       "9  세계  2023.03.15. 오후 4:03  데일리안  성병 갖고 태어났다...캐나다 '선천성 매독' 신생아 13배 급증, 이유는?   \n",
       "\n",
       "                                                  본문  \\\n",
       "0  우크라이나 전쟁에 남성 죄수들을 용병으로 투입했던 러시아가 여성 죄수들까지 전장에 ...   \n",
       "1  로이터=연합뉴스\\n\\n미국 실리콘밸리은행(SVB) 파산 사태에 조 바이든 미 행정부...   \n",
       "2  러 Su-27 전투기, 미 MQ-9 무인기 프로펠러 충돌\\n미 무인기 흑해 해상 추...   \n",
       "3  일본의 한 '쿠시카츠 다나카' 매장. (기사 내용과는 관련 없는 매장 사진)/'쿠시...   \n",
       "4  \"예비조사 단계…기소·고발 안 이어질 듯\"\\n파산 전 경영진 지분 매각 조사 대상\\...   \n",
       "5  포격당한 러시아 치하 우크라이나 볼노바카 마을, 군 조사관 모습 [자료사진]\\n우크...   \n",
       "6  감원 발표한 빅테크 중 첫 2차 구조조정\\n우선순위 낮은 프로젝트 폐기 계획도\\n2...   \n",
       "7  “최후의 수단으로 ‘기업 분할’ 검토”\\n글로벌 퇴출 우려에 자구책 고심\\n틱톡. ...   \n",
       "8  [중국 공업용 세제 원료로 해삼·전복 가공]\\n\\n중국 동북부 다롄의 한 수산물 업...   \n",
       "9  ⓒgettyimagesBank\\n[데일리안 = 박상우 기자] 캐나다에서 매독에 걸린...   \n",
       "\n",
       "                                                  링크  \n",
       "0  https://n.news.naver.com/mnews/article/055/000...  \n",
       "1  https://n.news.naver.com/mnews/article/366/000...  \n",
       "2  https://n.news.naver.com/mnews/article/469/000...  \n",
       "3  https://n.news.naver.com/mnews/article/023/000...  \n",
       "4  https://n.news.naver.com/mnews/article/119/000...  \n",
       "5  https://n.news.naver.com/mnews/article/214/000...  \n",
       "6  https://n.news.naver.com/mnews/article/011/000...  \n",
       "7  https://n.news.naver.com/mnews/article/011/000...  \n",
       "8  https://n.news.naver.com/mnews/article/055/000...  \n",
       "9  https://n.news.naver.com/mnews/article/119/000...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5bc078-d809-4534-ab8e-bacf9508c8e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a3d3c0c-5158-44c5-ac1e-21b766c582c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:18<00:00,  3.07s/it]\n"
     ]
    }
   ],
   "source": [
    "category = '정치'\n",
    "csv_path = 'C:/myPyCode/news_csv/'\n",
    "if f'{category}.csv' not in os.listdir(csv_path):\n",
    "    old_link2 = 0\n",
    "else:\n",
    "    f = open(csv_path + f'{category}.csv', mode='r',  encoding = 'utf-8')\n",
    "    file = csv.reader(f)\n",
    "    old_link = list(file)\n",
    "    old_link2 = [i[6] for i in old_link][1:]\n",
    "    f.close()\n",
    "\n",
    "for url in tqdm(politic_list):\n",
    "    page = 1\n",
    "    next_link_text = \"다음\"\n",
    "    link_list = []\n",
    "    while True:\n",
    "        page_url = url + str(page)\n",
    "\n",
    "        response = requests.get(page_url, headers={'User-Agent': 'Mozill4a/5.0'})\n",
    "        soup = bs4.BeautifulSoup(response.text, 'html.parser')\n",
    "        link = soup.select('td.content li dt a')\n",
    "        f_link_list = list(set([i.attrs['href'] for i in link]))\n",
    "        link_list.append(f_link_list)\n",
    "        addr = soup.find_all('a', {'class':'nclicks(fls.page)'})\n",
    "\n",
    "        next_button = soup.find('a', {'class':'next'})\n",
    "        if next_button:\n",
    "            page += 1\n",
    "\n",
    "        elif next_button is None:\n",
    "            numlist = [i.get_text() for i in addr][1:]\n",
    "            for page in numlist:\n",
    "                page_url = url + str(page)\n",
    "                response = requests.get(page_url, headers={'User-Agent': 'Mozill4a/5.0'})\n",
    "                soup = bs4.BeautifulSoup(response.text, 'html.parser')\n",
    "                link = soup.select('td.content li dt a')\n",
    "                f_link_list = list(set([i.attrs['href'] for i in link]))\n",
    "                link_list.append(f_link_list)\n",
    "            break\n",
    "\n",
    "link_list = [j for i in link_list for j in i]\n",
    "if old_link2 == 0:\n",
    "    total_link = link_list\n",
    "    additional_link = list(set(total_link))\n",
    "else:\n",
    "    total_link = old_link2 + link_list\n",
    "    total_link = list(set(total_link))\n",
    "    additional_link = [i for i in total_link if i not in old_link2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ff211fe-b31d-4faa-b520-e7b61b1cefb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "212"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(additional_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48b39b6b-ece4-4121-a159-a0a67898de22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "456"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(old_link2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec45adfb-fb6f-475b-a4d9-cd06bb34e9af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "668"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67451e7c-a450-4c8d-a255-e4ee2afd006d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee31aab-3e7f-4fe4-a416-9f5212dfffdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e7a03f-f185-4180-858e-a3cc27e50586",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7e94b3-c0d7-40a8-b90f-a3f0fb05603f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
